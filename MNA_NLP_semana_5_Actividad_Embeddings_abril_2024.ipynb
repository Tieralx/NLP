{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNl8G3vHkPSX"
      },
      "source": [
        "# **Maestría en Inteligencia Artificial Aplicada**\n",
        "\n",
        "## Curso: **Procesamiento de Lenguaje Natural**\n",
        "\n",
        "### Tecnológico de Monterrey\n",
        "\n",
        "### Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "## Adtividad Semana 5\n",
        "\n",
        "### **Vectores Embebidos Pre-entrenados: Fasttext**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U69mHA6i201G"
      },
      "source": [
        "#### **Nombres y matrículas de los integrantes del equipo:**\n",
        "\n",
        "\n",
        "\n",
        "*   Elemento de lista\n",
        "*   Elemento de lista\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\n",
            "ERROR: No matching distribution found for pickle\n"
          ]
        }
      ],
      "source": [
        "!pip install pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wCL2p6MA8NuT"
      },
      "outputs": [],
      "source": [
        "# Aquí deberás incluir todas las librerías que requieras durante esta actividad:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import  matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import WordNetLemmatizer as lemm\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import pickle\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c34ZOnna3Gu"
      },
      "source": [
        "##**Pregunta - 1:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeNllxRdmeWg"
      },
      "source": [
        "Descarga los 3 archivos de Canvas y genera un nuevo DataFrame de Pandas con ellos.\n",
        "\n",
        "**Llama simplemente \"df\" a dicho DataFrame.**\n",
        "\n",
        "Los archivos los encuentras en Canvas: amazon5.txt, imdb5.txt, yelp5.txt.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T_lyEFRkxzC6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "dfa = pd.read_csv('amazon5.txt', sep='\\t', names=['review','label'], header=None, encoding='utf-8')\n",
        "dfi = pd.read_csv('imdb5.txt', delimiter='   ', names=['review','label'], header=None, encoding='utf-8', engine='python')\n",
        "dfy = pd.read_csv('yelp5.txt', sep='\\t', names=['review','label'], header=None, encoding='utf-8')\n",
        "\n",
        "df = pd.concat([dfa, dfi, dfy], ignore_index=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3-w1xMLYnm9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3000 entries, 0 to 2999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   review  3000 non-null   object\n",
            " 1   label   3000 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 47.0+ KB\n"
          ]
        }
      ],
      "source": [
        "# Verifiquemos la información del DataFrame:\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NfVUcYe1nubT"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  label\n",
              "0  So there is no way for me to plug it in here i...      0\n",
              "1                        Good case, Excellent value.      1\n",
              "2                             Great for the jawbone.      1\n",
              "3  Tied to charger for conversations lasting more...      0\n",
              "4                                  The mic is great.      1"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Y veamos sus primeros registros:\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfZZ0stLmWJN"
      },
      "source": [
        "##**Pregunta - 2:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F6JF5BommZ6"
      },
      "source": [
        "Realiza el proceso de limpieza.\n",
        "\n",
        "Aplica el preprocesamiento que consideres adecuado, sin embargo, deberás aplicar necesariamente alguna de las técnicas de lematización.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TsnvMp-7oYCM"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "#wnl = nltk.WordNetLemmatizer()\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "def clean_tok(doc):\n",
        "    punctuation = string.punctuation\n",
        "    def remove_stops_digits(tokens):\n",
        "        return([token.lower() for token in tokens if token not in stopwords.words('english') and not token.isdigit() and token not in punctuation and len(token) > 1])\n",
        "    doc = re.sub(r'(?<=[.,])(?=[^\\s])', r' ', doc)\n",
        "    doc = re.sub('[\\!\\\"\\#\\$\\%\\&\\\\\\'\\(\\)\\*\\+\\,\\-\\.\\/:;\\<\\=\\>\\?\\@\\[\\\\\\\\\\]\\^\\_\\`\\{\\|\\}\\~]','',doc)\n",
        "    tmp_tok = nlp(doc)\n",
        "    tmp_tok = [token.lemma_ for token in tmp_tok]\n",
        "    tmp_tok = ' '.join(tmp_tok)\n",
        "    tokens = remove_stops_digits(word_tokenize(tmp_tok))\n",
        "    return(tokens)\n",
        "X = df.review     # Serie de strings\n",
        "Y = df.label      # Serie de enteros 0s y 1s\n",
        "Xclean = [clean_tok(x) for x in X] \n",
        "\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7jlQuoI2o33T"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['way', 'plug', 'us', 'unless', 'go', 'converter']\n",
            "['good', 'case', 'excellent', 'value']\n",
            "['great', 'jawbone']\n",
            "['tie', 'charger', 'conversation', 'last', 'minute', 'major', 'problems']\n",
            "['mic', 'great']\n",
            "['jiggle', 'plug', 'get', 'line', 'right', 'get', 'decent', 'volume']\n",
            "['several', 'dozen', 'several', 'hundred', 'contact', 'imagine', 'fun', 'send', 'one', 'one']\n",
            "['razr', 'owner', 'must']\n",
            "['needless', 'say', 'waste', 'money']\n",
            "['waste', 'money', 'time']\n",
            "['sound', 'quality', 'great']\n",
            "['impressed', 'go', 'original', 'battery', 'extended', 'battery']\n",
            "['two', 'seperate', 'mere', 'ft', 'start', 'notice', 'excessive', 'static', 'garbled', 'sound', 'headset']\n",
            "['good', 'quality', 'though']\n",
            "['design', 'odd', 'ear', 'clip', 'comfortable']\n",
            "['highly', 'recommend', 'one', 'blue', 'tooth', 'phone']\n",
            "['advise', 'everyone', 'fool']\n",
            "['far', 'good']\n",
            "['work', 'great']\n",
            "['click', 'place', 'way', 'make', 'wonder', 'long', 'mechanism', 'would', 'last']\n",
            "['go', 'motorolas', 'website', 'follow', 'direction', 'could', 'get', 'pair']\n",
            "['buy', 'use', 'kindle', 'fire', 'absolutely', 'love']\n",
            "['commercial', 'misleading']\n",
            "['yet', 'run', 'new', 'battery', 'two', 'bar', 'three', 'day', 'without', 'charge']\n",
            "['buy', 'mother', 'problem', 'battery']\n",
            "['great', 'pocket', 'pc', 'phone', 'combination']\n",
            "['phone', 'month', 'say', 'good', 'mobile', 'phone']\n",
            "['think', 'instruction', 'provide', 'helpful']\n",
            "['people', 'could', 'hear', 'talk', 'pull', 'earphone', 'talk', 'phone']\n",
            "['hold', 'charge']\n",
            "['simple', 'little', 'phone', 'use', 'breakage', 'unacceptible']\n",
            "['product', 'ideal', 'people', 'like', 'whose', 'ear', 'sensitive']\n",
            "['unusable', 'move', 'car', 'freeway', 'speed']\n",
            "['two', 'year', 'leave', 'contract', 'hate', 'phone']\n",
            "['car', 'charger', 'well', 'ac', 'charger', 'include', 'make', 'sure', 'never', 'run', 'juice', 'highy', 'recommend']\n",
            "['need', 'least', 'min', 'get', 'phone', 'book', 'time', 'first', 'turn', 'phone', 'battery', 'life', 'short']\n",
            "['keep', 'well']\n",
            "['poor', 'talk', 'time', 'performance']\n",
            "['case', 'great', 'work', 'fine']\n",
            "['worthless', 'product']\n",
            "['great', 'camera', '2mp', 'pic', 'nice', 'clear', 'great', 'picture', 'quality']\n",
            "['impressed', 'product']\n",
            "['nice', 'headset', 'price', 'right']\n",
            "['hear', 'garbage', 'audio']\n",
            "['excellent', 'bluetooth', 'headset']\n",
            "['feature', 'want']\n",
            "['right', 'mind', 'go', 'buy', 'battery']\n",
            "['argue', 'verizon', 'regard', 'dropped', 'call', 'return', 'phones', 'two', 'day']\n",
            "['case', 'seem', 'well', 'make']\n",
            "['disappoint', 'battery']\n"
          ]
        }
      ],
      "source": [
        "# Despleguemos los primeros comentarios después de tu proceso de limpieza:\n",
        "\n",
        "for x in Xclean[0:50]:\n",
        "  print(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygchEdcKqIzU"
      },
      "source": [
        "#**Pregunta - 3:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wEIOkkl9Dot"
      },
      "source": [
        "\n",
        "Realicemos una partición aleatoria con los mismos porcentajes de la práctica pasada para poder comparar dichos resultados con los de\n",
        "esta actividad, a saber, 70%, 15% y 15%, para entrenamiento, validación y prueba, respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b0SAcYdq9X0w"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X,y Train: 2100 2100\n",
            "X,y Val: 450 450\n",
            "X,y Test 450 450\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ************* Inicia la sección de agregar código:*****************************\n",
        "\n",
        "x_train, x_val_and_test, y_train, y_val_and_test = train_test_split(Xclean, Y, train_size=.70, shuffle=True, random_state=1) \n",
        "x_val, x_test, y_val, y_test = train_test_split(x_val_and_test, y_val_and_test, test_size=.50, shuffle=True, random_state=17)\n",
        "\n",
        "# *********** Termina la sección de agregar código *************\n",
        "\n",
        "\n",
        "# verificemos las dimensiones obtenidas:\n",
        "print('X,y Train:', len(x_train), len(y_train))\n",
        "print('X,y Val:', len(x_val), len(y_val))\n",
        "print('X,y Test', len(x_test), len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qjKoEqiqBN1"
      },
      "source": [
        "#**Pregunta - 4:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jENsKiN99r3F"
      },
      "source": [
        "\n",
        "\n",
        "Construye tu vocabulario a continuación\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TzJntmLPqPqC"
      },
      "outputs": [],
      "source": [
        "# a.\tUsa el conjunto de entrenamiento para generar tu vocabulario\n",
        "#     con un tamaño que consideres adecuado:\n",
        "\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "my_dictionary = Counter()    \n",
        "\n",
        "for k in range(len(x_train)):\n",
        "    my_dictionary.update(x_train[k])\n",
        "\n",
        "min_freq = 2\n",
        "my_dictionary = {word: freq for word, freq in my_dictionary.items() if freq >= min_freq}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yTDZ0Rr86CUP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Longitud del vocabulario generado:\n",
            "Vocabulario: 1395\n"
          ]
        }
      ],
      "source": [
        "# b.\tIndica el tamaño del vocabulario generado.\n",
        "\n",
        "print('Longitud del vocabulario generado:')\n",
        "\n",
        "\n",
        "# ******* Inicia la sección de agregar código: ***********\n",
        "\n",
        "\n",
        "print('Vocabulario:', len(my_dictionary))  \n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDa4EhTqrw15"
      },
      "source": [
        "c.\t¿Por qué debe usarse solamente el conjunto de entrenamiento para generar el vocabulario?\n",
        "\n",
        "\n",
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "None\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto: +++++++++++\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7ykjxQI3rpxx"
      },
      "outputs": [],
      "source": [
        "# d.\tCon el vocabulario generado, filtra los conjuntos de entrenamiento,\n",
        "#     validación y prueba para que todos los comentarios usen solamente las\n",
        "#     palabras de este vocabulario.\n",
        "\n",
        "#     Llamar train_x, val_x y test_x a estos tres conjuntos.\n",
        "\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "\n",
        "train_x = []\n",
        "for ss in x_train:\n",
        "    train_x.append([w for w in ss if w in my_dictionary])\n",
        "\n",
        "val_x = []\n",
        "for ss in x_val:\n",
        "    val_x.append([w for w in ss if w in my_dictionary])\n",
        "\n",
        "test_x = []\n",
        "for ss in x_test:\n",
        "    test_x.append([w for w in ss if w in my_dictionary])\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iYF2RGuPtQTC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['fare', 'much', 'well', 'people', 'like', 'morgan', 'ed', 'waste']\n",
            "['tonight', 'filet', 'special', 'suck']\n",
            "['pay', 'bill', 'tip', 'feel', 'server', 'terrible', 'job']\n",
            "['call', 'properly', 'cook', 'steak', 'understand']\n",
            "['however', 'keypad', 'tinny', 'sometimes', 'reach', 'wrong', 'button']\n"
          ]
        }
      ],
      "source": [
        "# Vemos el resultado de los primeros comentarios del conjunto de entrenamiento:\n",
        "\n",
        "for ss in train_x[0:5]:\n",
        "  print(ss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS0Hxj25vTWh"
      },
      "source": [
        "#**Pregunta - 5:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnHHAza5_P5Z"
      },
      "source": [
        "\n",
        "a. Incluye una tabla comparativa de pros y contras entre los modelos FastText, word2vec de Google y Glove de Stanford."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTI9xSgF_Xc8"
      },
      "source": [
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "None\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto: +++++++++++\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToqRl7fT_fn2"
      },
      "source": [
        "#**Pregunta - 6:**\n",
        "\n",
        "Utiliza el modelo FastText de vectores embebidos pre-entrenados de dimensión 300 para generar un nuevo diccionario clave-valor, donde la “clave” será cada token o palabra de tu vocabulario y el “valor” será su vector embebido de dimensión 300.\n",
        "\n",
        "Este diccionario deberá ser del mismo tamaño que el vocabulario previo que hayas construido previamente.\n",
        "\n",
        "Es recomendable que una vez que generes el nuevo vocabulario de vectores embebidos, guardes dicho diccionario en un archivo.\n",
        "\n",
        "Recuerda borrar la variable donde descargaste los 2 millones de vectores embebidos Fasttext.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UdK-jMfLxHLY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "\n",
        "fasttext.util.download_model('en', if_exists='ignore')\n",
        "ft = fasttext.load_model('cc.en.300.bin')\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamaño del Vocabulario antes de Embeddings: 1395\n",
            "Tamaño del Vocabulario después de Embeddings: 1395\n"
          ]
        }
      ],
      "source": [
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "\n",
        "print(f'Tamaño del Vocabulario antes de Embeddings: {len(my_dictionary)}')\n",
        "\n",
        "# Obtener los tokens\n",
        "tokens = list(my_dictionary.keys())\n",
        "\n",
        "# Crear un nuevo diccionario para los Embeddings\n",
        "embedded_dict = {}\n",
        "\n",
        "# Iterar sobre el vocabulario\n",
        "for token in tokens:\n",
        "    try:\n",
        "        # Intentar obtener el vector directamente del modelo FastText\n",
        "        embedded_dict[token] = ft.get_word_vector(token)\n",
        "    except KeyError:\n",
        "        # Si el token no está en el modelo, buscar el vector más cercano\n",
        "        nearest_neighbors = ft.get_nearest_neighbors(token, k=1)\n",
        "        nearest_token, _ = nearest_neighbors[0]\n",
        "        embedded_dict[token] = ft.get_word_vector(nearest_token)\n",
        "\n",
        "# Guardar el vocabulario con Embeddings en un archivo pickle\n",
        "with open('embedded_dict.pkl', 'wb') as f:\n",
        "    pickle.dump(embedded_dict, f)\n",
        "\n",
        "# Se borra la variable de FastText para liberar memoria RAM\n",
        "del ft\n",
        "\n",
        "print(f'Tamaño del Vocabulario después de Embeddings: {len(embedded_dict)}')\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4S7q0yR0Mpi"
      },
      "source": [
        "#**Pregunta - 7:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyeOrkoaC1eq"
      },
      "source": [
        "\n",
        "\n",
        "Generamos los vectores embebidos a paertir de los conjuntos de entrenamiento, validación y preuba.\n",
        "\n",
        "Los llamaremos trainEmb, valEmb y testEmb, respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wnfQpkxg0Usq"
      },
      "outputs": [],
      "source": [
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "# Cargar el diccionario de Embeddings\n",
        "with open('embedded_dict.pkl', 'rb') as f:\n",
        "    embedded_dict = pickle.load(f)\n",
        "\n",
        "def avg_embedding(docs, embedding_dict):\n",
        "    # Obtener vectores correspondientes\n",
        "    embeddings = [embedding_dict[token] for token in docs]\n",
        "    # Calcular el promedio\n",
        "    return np.mean(embeddings, axis=0) if embeddings else np.zeros(300)\n",
        "\n",
        "# Aplicar a cada conjunto\n",
        "trainEmb = np.array([avg_embedding(comment, embedded_dict) for comment in train_x])\n",
        "valEmb = np.array([avg_embedding(comment, embedded_dict) for comment in val_x])\n",
        "testEmb = np.array([avg_embedding(comment, embedded_dict) for comment in test_x])\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "J3BBF96D0N8Z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train-Emb: (2100, 300)\n",
            "Val-Emb: (450, 300)\n",
            "Test-Emb: (450, 300)\n"
          ]
        }
      ],
      "source": [
        "# Veamos las dimensiones de cada conjunto embebido:\n",
        "\n",
        "print(\"Train-Emb:\", trainEmb.shape)\n",
        "print(\"Val-Emb:\", valEmb.shape)\n",
        "print(\"Test-Emb:\", testEmb.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pibp1LA91CP_"
      },
      "source": [
        "#**Pregunta - 8:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxC9K0VnGOwG"
      },
      "source": [
        "\n",
        "Utiliza los modelos de regresión logística y bosque aleatorio (random forest) y encuentra sus desempeños.\n",
        "\n",
        "Compara los resultados con los de la semana anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ycwjD8ztGOL7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR: Train-accuracy: 81.00%\n",
            "LR: Val-accuracy: 78%\n",
            "LR: Test-accuracy: 80%\n"
          ]
        }
      ],
      "source": [
        "# REGRESIÓN LOGÍSTICA:\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "modeloLRemb = LogisticRegression(C = 1, max_iter = 10000, solver='saga')\n",
        "modeloLRemb.fit(trainEmb, y_train)\n",
        "\n",
        "print('LR: Train-accuracy: %.2f%%' % (100*modeloLRemb.score(trainEmb, y_train)))\n",
        "print('LR: Val-accuracy: %2.f%%' % (100*modeloLRemb.score(valEmb, y_val)))\n",
        "print('LR: Test-accuracy: %2.f%%' % (100*modeloLRemb.score(testEmb, y_test)))\n",
        "\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "N4n70GHW0sl3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RF: Train-accuracy: 99.29%\n",
            "RF: Val-accuracy: 77.56%\n",
            "RF: Test-accuracy: 78.44%\n"
          ]
        }
      ],
      "source": [
        "# BOSQUE ALEATORIO (Random Forest):\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "modeloRFemb = RandomForestClassifier(n_estimators=10000, max_depth = 1000, min_samples_split = 2, n_jobs = -1)\n",
        "modeloRFemb.fit(trainEmb, y_train)\n",
        "\n",
        "print('RF: Train-accuracy: %.2f%%' % (100*modeloRFemb.score(trainEmb, y_train)))\n",
        "print('RF: Val-accuracy: %.2f%%' % (100*modeloRFemb.score(valEmb, y_val)))\n",
        "print('RF: Test-accuracy: %.2f%%' % (100*modeloRFemb.score(testEmb, y_test)))\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDIiSHvg0_hm"
      },
      "source": [
        "#**Pregunta - 9:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJJtALGZHrGk"
      },
      "source": [
        "\n",
        "\n",
        "Reporte del mejor modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ETv4VLjP1GYt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Matriz de confusión con el mejor modelo:\n",
            "[[173  43]\n",
            " [ 46 188]]\n",
            "\n",
            "Matriz de confusión con el mejor modelo en proporciones:\n",
            "[[0.38444444 0.09555556]\n",
            " [0.10222222 0.41777778]]\n"
          ]
        }
      ],
      "source": [
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "\n",
        "best_model = modeloLRemb\n",
        "\n",
        "pred = best_model.predict(testEmb)\n",
        "print('\\nMatriz de confusión con el mejor modelo:')\n",
        "print(confusion_matrix(y_test, pred, labels=[0,1]))\n",
        "\n",
        "print('\\nMatriz de confusión con el mejor modelo en proporciones:')\n",
        "print(confusion_matrix(y_test, pred, labels=[0,1]) / pred.shape[0])\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCkh2WfN1MC1"
      },
      "source": [
        "#**Pregunta - 10:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ySFuDQtVuK5"
      },
      "source": [
        "\n",
        "\n",
        "Incluye tus comentarios finales de la actividad.\n",
        "\n",
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "None\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto: +++++++++++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgKHmQTbWJT1"
      },
      "source": [
        "##**Fin de la Actividad de vectores Embebidos - FastText**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
